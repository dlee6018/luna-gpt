{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837595ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size:int = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa3bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "fineweb = load_dataset(\n",
    "    \"HuggingFaceFW/fineweb\", \n",
    "    \"sample-10BT\", \n",
    "    split=\"train\",\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "print(\"Hello\")\n",
    "print(fineweb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c64dbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2020 gRPC authors.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\"\"\"The Python AsyncIO implementation of the GRPC helloworld.Greeter server.\"\"\"\n",
      "\n",
      "import logging\n",
      "import asyncio\n",
      "import grpc\n",
      "\n",
      "import helloworld_pb2\n",
      "import helloworld_pb2_grpc\n",
      "\n",
      "\n",
      "class Greeter(helloworld_pb2_grpc.GreeterServicer):\n",
      "\n",
      "    async def SayHello(\n",
      "            self, request: helloworld_pb2.HelloRequest,\n",
      "            context: grpc.aio.ServicerContext) -> helloworld_pb2.HelloReply:\n",
      "        return helloworld_pb2.HelloReply(message='Hello, %s!' % request.name)\n",
      "\n",
      "\n",
      "async def serve() -> None:\n",
      "    server = grpc.aio.server()\n",
      "    helloworld_pb2_grpc.add_GreeterServicer_to_server(Greeter(), server)\n",
      "    listen_addr = '[::]:50051'\n",
      "    server.add_insecure_port(listen_addr)\n",
      "    logging.info(\"Starting server on %s\", listen_addr)\n",
      "    await server.start()\n",
      "    try:\n",
      "        await server.wait_for_termination()\n",
      "    except KeyboardInterrupt:\n",
      "        # Shuts down the server with 0 seconds of grace period. During the\n",
      "        # grace period, the server won't accept new connections and allow\n",
      "        # existing RPCs to continue within the grace period.\n",
      "        await server.stop(0)\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    logging.basicConfig(level=logging.INFO)\n",
      "    asyncio.run(serve())\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\n",
    "    \"bigcode/the-stack-smol\", \n",
    "    data_dir=\"data/python\", \n",
    "    split=\"train\", \n",
    "    streaming=True\n",
    ")\n",
    "x = iter(ds)\n",
    "elem = next(x)\n",
    "print(elem['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfec8ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Machine Learning is designed to be simple to use, but highly versatile and flexible in its use. For example, it can be used to design and build custom architectures for applications in Java, C#, C++, Python, Ruby, PHP, and other languages. It is also very modular, and can be used in a wide range of environments.\\n\\nThe goal of this project is to provide a simple way to build open source, user-friendly code that is easy to learn and use, with a minimal effort and with minimal overhead.\\n\\nIn addition, this project allows you to build a large number of open source libraries and technologies. It is also able to build new libraries for a wide variety of different devices, and to build applications that rely on the features of the Open Source community to run on them.\\n\\nIf you want to learn more, see the documentation on the project here.'},\n",
       " {'generated_text': \"Machine Learning is the research and development effort of the University of Michigan. It employs over 250 researchers and engineers for more than 35 years. The University's goal is to be a leader in the field of artificial intelligence in ways that enable our future generations to explore the potential of AI to solve complex problems.\\n\\nMore information on this program can be found on the University's website.\"},\n",
       " {'generated_text': 'Machine Learning is a powerful and fast open-source framework for managing large-scale neural networks.\\n\\nThis framework is designed to be used in many different applications, from learning algorithms to training neural networks. It is designed to be a single, unified set of tools that can be used to build and test large-scale neural networks.\\n\\nIt is designed to be a single, unified set of tools that can be used to build and test large-scale neural networks. It is designed to be a single, unified set of tools that can be used to build and test large-scale neural networks. The framework is also modular and can be used to build and test large-scale networks.'},\n",
       " {'generated_text': 'Machine Learning is very similar to Python, but much more powerful. It has a number of interesting features that are not available in Python:\\n\\nSimplicity of construction\\n\\nNo need to worry about complex code\\n\\nNo need to worry about hard-coded variables\\n\\nIf you are interested in learning more about learning Python, here is a quick guide to the Python language:\\n\\nhttp://pypi.python.org/pypi/learn/\\n\\nAnd here is a quick Python tutorial on learning Python:\\n\\nhttp://code.google.com/p/python/issues/detail?id=83675\\n\\nFinally, here are some Python tutorials you may want to check out:'},\n",
       " {'generated_text': 'Machine Learning is a great tool that can be used to train and learn on a scale that is never going to be able to match with your expectations.\\n\\n\\nTo learn more about how to get started with Machine Learning, check out our Machine Learning Tutorials, or subscribe to our newsletter to receive updates on Machine Learning.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Machine Learning is\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a1faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
